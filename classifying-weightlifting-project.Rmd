---
title: "Classifying Weightlifting Project"
author: "Fabio Sena"
date: "22 de abril de 2017"
output: github_document
---
```{r setup, include=FALSE, echo=TRUE}
knitr::opts_chunk$set(echo = TRUE)
options(scipen = 999)
```

```{r Packages, message=FALSE, warning=FALSE}
# Packages
required.packages <- c("data.table", "ggplot2", "caret", "rpart", "rpart.plot", "randomForest", "e1071")
load.or.install.package <- function(x) {
  if (!require(x, character.only=TRUE)) {
    install.packages(x)
    library(x)
    "Installed and Loaded"
  } else {
    "Loaded"
  }
}
sapply(required.packages, load.or.install.package)

# Reproducability
set.seed(997)

```

```{r DownloadingAndLoadingDatasets}

# Data
training_file_name   <- './data/pml-training.csv'
testing_file_name <- './data/pml-testing.csv'

# Directories
setwd("C:\\DataCamp\\classifying-weightlifting-project")
if (!file.exists("data")) (dir.create("data"))
if (!file.exists("submission")) dir.create("submission")

if(!file.exists(training_file_name)) 
  download.file('http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv', training_file_name, quiet = FALSE)

if(!file.exists(testing_file_name)) 
  download.file('http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv', testing_file_name, quiet = FALSE)

# Load datasets
na.strings <- c("NA","#DIV/0!", "")
pml_training <- fread(training_file_name, na.strings = na.strings, sep = ",")
pml_testing <-fread(testing_file_name , na.strings = na.strings)

pml_training <- pml_training[,-c(1:7)]
pml_testing  <- pml_testing[,-c(1:7)]  

# Data cleaning
pml_training <- pml_training[, colSums(is.na(pml_training)) == 0, with = FALSE]
pml_testing <- pml_testing[, colSums(is.na(pml_testing)) == 0, with = FALSE]

```

## Overview ##

This report examines the Weight Lifting Exercises (WLE) Dataset to predict the quality of lifting weights from activity monitors. The quality is represented by the variable class that has 5 levels:

* Class A: according to the specification 
* Class B: elbows to the front 
* Class C: lifting halfway
* Class D: lowering halfway
* Class E: hips to the front

## Preparing data for training and testing ##

Creating a 60%/40% train and test split.

```{r Preparing}
# Spliting training and testing sets
indexes <- createDataPartition(y = pml_training$classe, p=0.6, list = FALSE)
training_set <- pml_training[indexes, ] 
testing_set <- pml_training[-indexes, ]
```

## Exploratory analysis ##
```{r}
# Training set
ggplot(training_set, aes(x = classe, fill = classe)) + geom_bar() + scale_fill_brewer(palette="Spectral")

# Testing set
ggplot(testing_set, aes(x = classe, fill = classe)) + geom_bar() + scale_fill_brewer(palette="Dark2")
```
The plot shows how the classes are distributed in the dataset.

## Prediction models ##

### Decision Tree ###

First we train (fit) the classification tree model on the training set, plot model tree, predict the classification on testing set and show the confution matrix.

```{r DecisionTree}
# Train Classification Tree Model
tree_model <- rpart(classe ~ ., data = training_set, method="class")

# Plot Classification Tree
rpart.plot(tree_model, main="Classification Tree", extra=102, under=TRUE, faclen=0)

# Prediction Classification Tree model
tree_model_predicted <- predict(tree_model, testing_set, type = "class")

# Show Classification Tree confusion matrix
confusion_matrix_tree_model <- confusionMatrix(tree_model_predicted, testing_set$classe)
confusion_matrix_tree_model
tree_model_error <- 1 - confusion_matrix_tree_model$overall['Accuracy']
```

#### Classification Tree Model Error ####

```{r}
sprintf("Classification Tree Model Error: %3.2f", tree_model_error * 100)
```

### Random Forest ###

Then we train (fit) the random forest model on the training set, plot model tree, predict the classification on testing set and show the confution matrix. During preprocessing, principal component analysis (PCA) is used to reduce the dimensionality of the data (feature reduction) while preserving the data's essential variance. With the cv method parameter, we tune the training function to use k-folds cross validation.

```{r RandomForest}
# Fit model
train_control <- trainControl(method="cv", number=5, verboseIter = FALSE , preProcOptions="pca")
random_forest_model <- train(classe ~ ., data = training_set, method="rf", trControl = train_control, ntree = 50)

# Perform prediction
random_forest_predicted <- predict(random_forest_model, testing_set, type = "raw")

# Show Random forest confusion matrix
confusion_matrix_random_forest <- confusionMatrix(random_forest_predicted, testing_set$classe)
random_forest_error <- 1 - confusion_matrix_random_forest$overall['Accuracy']
```

#### Random Forest Model Error ####

```{r}
sprintf("Random Forest Model Error: %3.2f", random_forest_error * 100)
```

### Test Case ###

Finale we predict final pml testing set and write the submission since the random forest model proved to be the most accurate.

```{r TestCase}
final_predict <- predict(random_forest_model, pml_testing)

write.csv(as.data.table(final_predict), "./submission/submission.csv")
```

## Citations ##

Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks,
H. Qualitative Activity Recognition of Weight Lifting
Exercises. Proceedings of 4th International Conference in Cooperation
with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI,
2013.
